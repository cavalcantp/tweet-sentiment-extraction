{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF version 2.7.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd, numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from transformers import *\n",
    "import tokenizers\n",
    "print('TF version',tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 96\n",
    "PATH = '../config/'\n",
    "\n",
    "tokenizer = tokenizers.ByteLevelBPETokenizer(\n",
    "    vocab=PATH+'vocab-roberta-base.json', \n",
    "    merges=PATH+'merges-roberta-base.txt', \n",
    "    lowercase=True,\n",
    "    add_prefix_space=True\n",
    ")\n",
    "sentiment_id = {'positive': 1313, 'negative': 2430, 'neutral': 7974}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Recession hit Veronique Branquinho, she has to quit her company, such a shame!'"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.loc[2, 'text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing\n",
    "test = pd.read_csv('test.csv').fillna('')\n",
    "tweet = test.loc[2, 'text'] #'Last session of the day  http://twitpic.com/67ezh'\n",
    "sentiment = 'negative'\n",
    "ct = 1\n",
    "input_ids = np.ones((ct,MAX_LEN),dtype='int32')\n",
    "attention_mask = np.zeros((ct,MAX_LEN),dtype='int32')\n",
    "token_type_ids = np.zeros((ct,MAX_LEN),dtype='int32')\n",
    "\n",
    "# INPUT_IDS\n",
    "text1 = \" \"+\" \".join(tweet.split())\n",
    "enc = tokenizer.encode(text1)\n",
    "s_tok = sentiment_id[sentiment]           \n",
    "input_ids[0,:len(enc.ids)+5] = [0] + enc.ids + [2,2] + [s_tok] + [2]\n",
    "attention_mask[0,:len(enc.ids)+5] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    ids = tf.keras.layers.Input((MAX_LEN,), dtype=tf.int32)\n",
    "    att = tf.keras.layers.Input((MAX_LEN,), dtype=tf.int32)\n",
    "    tok = tf.keras.layers.Input((MAX_LEN,), dtype=tf.int32)\n",
    "\n",
    "    config = RobertaConfig.from_pretrained(PATH+'config-roberta-base.json')\n",
    "    bert_model = TFRobertaModel.from_pretrained(PATH+'pretrained-roberta-base.h5',config=config)\n",
    "    x = bert_model(ids,attention_mask=att,token_type_ids=tok)\n",
    "    \n",
    "    x1 = tf.keras.layers.Dropout(0.1)(x[0]) \n",
    "    x1 = tf.keras.layers.Conv1D(1,1)(x1)\n",
    "    x1 = tf.keras.layers.Flatten()(x1)\n",
    "    x1 = tf.keras.layers.Activation('softmax')(x1)\n",
    "    \n",
    "    x2 = tf.keras.layers.Dropout(0.1)(x[0]) \n",
    "    x2 = tf.keras.layers.Conv1D(1,1)(x2)\n",
    "    x2 = tf.keras.layers.Flatten()(x2)\n",
    "    x2 = tf.keras.layers.Activation('softmax')(x2)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs=[ids, att, tok], outputs=[x1,x2])\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=3e-5)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFRobertaModel.\n",
      "\n",
      "All the layers of TFRobertaModel were initialized from the model checkpoint at ../config/pretrained-roberta-base.h5.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "model = build_model()\n",
    "model.load_weights(\"../weights_final.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 7s 7s/step\n"
     ]
    }
   ],
   "source": [
    "DISPLAY = 1\n",
    "preds = model.predict([input_ids, attention_mask, token_type_ids],verbose=DISPLAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 96)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_start = np.zeros((input_ids.shape[0],MAX_LEN))\n",
    "preds_end = np.zeros((input_ids.shape[0],MAX_LEN))\n",
    "skf = StratifiedKFold(n_splits=5,shuffle=True,random_state=777)\n",
    "preds_start += preds[0] #/skf.n_splits\n",
    "preds_end += preds[1] #/skf.n_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(preds_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "all = []\n",
    "for k in range(input_ids.shape[0]):\n",
    "    a = np.argmax(preds_start[k,])\n",
    "    b = np.argmax(preds_end[k,])\n",
    "    if a>b: \n",
    "        st = tweet\n",
    "    else:\n",
    "        text1 = \" \"+\" \".join(tweet.split())\n",
    "        print(text1)\n",
    "        enc = tokenizer.encode(text1)\n",
    "        print(enc.ids)\n",
    "        print(a-1, b)\n",
    "        st = tokenizer.decode(enc.ids[a-1:b])\n",
    "    all.append(st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Today after school, I saw a lost puppy, so sad!']"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.argmax(preds_start[0,])\n",
    "b = np.argmax(preds_end[0,])\n",
    "if a>b: \n",
    "    selected_text = tweet\n",
    "else:\n",
    "    text1 = \" \"+\" \".join(tweet.split())\n",
    "    print(text1)\n",
    "    enc = tokenizer.encode(text1)\n",
    "    print(enc.ids)\n",
    "    print(a-1, b)\n",
    "    selected_text = tokenizer.decode(enc.ids[a-1:b])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(enc.ids[max(a-1, 0):b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = train.shape[0]\n",
    "input_ids = np.ones((ct,MAX_LEN),dtype='int32')\n",
    "attention_mask = np.zeros((ct,MAX_LEN),dtype='int32')\n",
    "token_type_ids = np.zeros((ct,MAX_LEN),dtype='int32')\n",
    "start_tokens = np.zeros((ct,MAX_LEN),dtype='int32')\n",
    "end_tokens = np.zeros((ct,MAX_LEN),dtype='int32')\n",
    "\n",
    "for k in range(train.shape[0]):\n",
    "    \n",
    "    # FIND OVERLAP\n",
    "    text1 = \" \"+\" \".join(train.loc[k,'text'].split())\n",
    "    text2 = \" \".join(train.loc[k,'selected_text'].split())\n",
    "    idx = text1.find(text2)\n",
    "    chars = np.zeros((len(text1)))\n",
    "    chars[idx:idx+len(text2)]=1\n",
    "    if text1[idx-1]==' ': chars[idx-1] = 1 \n",
    "    enc = tokenizer.encode(text1) \n",
    "        \n",
    "    # ID_OFFSETS\n",
    "    offsets = []; idx=0\n",
    "    for t in enc.ids:\n",
    "        w = tokenizer.decode([t])\n",
    "        offsets.append((idx,idx+len(w)))\n",
    "        idx += len(w)\n",
    "    \n",
    "    # START END TOKENS\n",
    "    toks = []\n",
    "    for i,(a,b) in enumerate(offsets):\n",
    "        sm = np.sum(chars[a:b])\n",
    "        if sm>0: toks.append(i) \n",
    "        \n",
    "    s_tok = sentiment_id[train.loc[k,'sentiment']]\n",
    "    input_ids[k,:len(enc.ids)+5] = [0] + enc.ids + [2,2] + [s_tok] + [2]\n",
    "    attention_mask[k,:len(enc.ids)+5] = 1\n",
    "    if len(toks)>0:\n",
    "        start_tokens[k,toks[0]+1] = 1\n",
    "        end_tokens[k,toks[-1]+1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('test.csv').fillna('')\n",
    "\n",
    "ct = test[:10].shape[0]\n",
    "input_ids_t = np.ones((ct,MAX_LEN),dtype='int32')\n",
    "attention_mask_t = np.zeros((ct,MAX_LEN),dtype='int32')\n",
    "token_type_ids_t = np.zeros((ct,MAX_LEN),dtype='int32')\n",
    "\n",
    "for k in range(test[:10].shape[0]):\n",
    "        \n",
    "    # INPUT_IDS\n",
    "    text1 = \" \"+\" \".join(test.loc[k,'text'].split())\n",
    "    enc = tokenizer.encode(text1)                \n",
    "    s_tok = sentiment_id[test.loc[k,'sentiment']]\n",
    "    input_ids_t[k,:len(enc.ids)+5] = [0] + enc.ids + [2,2] + [s_tok] + [2]\n",
    "    attention_mask_t[k,:len(enc.ids)+5] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard(str1, str2): \n",
    "    a = set(str1.lower().split()) \n",
    "    b = set(str2.lower().split())\n",
    "    if (len(a)==0) & (len(b)==0): return 0.5\n",
    "    c = a.intersection(b)\n",
    "    return float(len(c)) / (len(a) + len(b) - len(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########################\n",
      "### FOLD 1\n",
      "#########################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFRobertaModel.\n",
      "\n",
      "All the layers of TFRobertaModel were initialized from the model checkpoint at ../config/pretrained-roberta-base.h5.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...\n",
      "Predicting Test...\n",
      "WARNING:tensorflow:5 out of the last 10 calls to <function Model.make_predict_function.<locals>.predict_function at 0x1390d88b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 8s 8s/step\n",
      "#########################\n",
      "### FOLD 2\n",
      "#########################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFRobertaModel.\n",
      "\n",
      "All the layers of TFRobertaModel were initialized from the model checkpoint at ../config/pretrained-roberta-base.h5.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...\n",
      "Predicting Test...\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x1358f1280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 8s 8s/step\n",
      "#########################\n",
      "### FOLD 3\n",
      "#########################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFRobertaModel.\n",
      "\n",
      "All the layers of TFRobertaModel were initialized from the model checkpoint at ../config/pretrained-roberta-base.h5.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...\n",
      "Predicting Test...\n",
      "1/1 [==============================] - 10s 10s/step\n",
      "#########################\n",
      "### FOLD 4\n",
      "#########################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFRobertaModel.\n",
      "\n",
      "All the layers of TFRobertaModel were initialized from the model checkpoint at ../config/pretrained-roberta-base.h5.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...\n",
      "Predicting Test...\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "#########################\n",
      "### FOLD 5\n",
      "#########################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFRobertaModel.\n",
      "\n",
      "All the layers of TFRobertaModel were initialized from the model checkpoint at ../config/pretrained-roberta-base.h5.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...\n",
      "Predicting Test...\n",
      "1/1 [==============================] - 8s 8s/step\n"
     ]
    }
   ],
   "source": [
    "jac = []; VER='v0'; DISPLAY=1 # USE display=1 FOR INTERACTIVE\n",
    "oof_start = np.zeros((input_ids.shape[0],MAX_LEN))\n",
    "oof_end = np.zeros((input_ids.shape[0],MAX_LEN))\n",
    "preds_start = np.zeros((input_ids_t.shape[0],MAX_LEN))\n",
    "preds_end = np.zeros((input_ids_t.shape[0],MAX_LEN))\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5,shuffle=True,random_state=777)\n",
    "for fold in range(skf.n_splits):#,(idxT,idxV) in enumerate(skf.split(input_ids,train.sentiment.values)):\n",
    "\n",
    "    print('#'*25)\n",
    "    print('### FOLD %i'%(fold+1))\n",
    "    print('#'*25)\n",
    "    \n",
    "    K.clear_session()\n",
    "    model = build_model()\n",
    "        \n",
    "    #sv = tf.keras.callbacks.ModelCheckpoint(\n",
    "    #    '%s-roberta-%i.h5'%(VER,fold), monitor='val_loss', verbose=1, save_best_only=True,\n",
    "    #    save_weights_only=True, mode='auto', save_freq='epoch')\n",
    "        \n",
    "    #model.fit([input_ids[idxT,], attention_mask[idxT,], token_type_ids[idxT,]], [start_tokens[idxT,], end_tokens[idxT,]], \n",
    "    #    epochs=3, batch_size=32, verbose=DISPLAY, callbacks=[sv],\n",
    "    #    validation_data=([input_ids[idxV,],attention_mask[idxV,],token_type_ids[idxV,]], \n",
    "    #    [start_tokens[idxV,], end_tokens[idxV,]]))\n",
    "    \n",
    "    print('Loading model...')\n",
    "    model.load_weights(\"../weights_final.h5\") #('%s-roberta-%i.h5'%(VER,fold))\n",
    "    \n",
    "    #print('Predicting OOF...')\n",
    "    #oof_start[idxV,],oof_end[idxV,] = model.predict([input_ids[idxV,],attention_mask[idxV,],token_type_ids[idxV,]],verbose=DISPLAY)\n",
    "    \n",
    "    print('Predicting Test...')\n",
    "    preds = model.predict([input_ids_t,attention_mask_t,token_type_ids_t],verbose=DISPLAY)\n",
    "    preds_start += preds[0]/skf.n_splits\n",
    "    preds_end += preds[1]/skf.n_splits\n",
    "    \n",
    "    # DISPLAY FOLD JACCARD\n",
    "    #all = []\n",
    "    #for k in idxV:\n",
    "    #    a = np.argmax(oof_start[k,])\n",
    "    #    b = np.argmax(oof_end[k,])\n",
    "    #    if a>b: \n",
    "    #        st = train.loc[k,'text'] # IMPROVE CV/LB with better choice here\n",
    "    #    else:\n",
    "    #        text1 = \" \"+\" \".join(train.loc[k,'text'].split())\n",
    "    #        enc = tokenizer.encode(text1)\n",
    "    #        st = tokenizer.decode(enc.ids[a-1:b])\n",
    "    #    all.append(jaccard(st,train.loc[k,'selected_text']))\n",
    "    #jac.append(np.mean(all))\n",
    "    #print('>>>> FOLD %i Jaccard ='%(fold+1),np.mean(all))\n",
    "    #print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "all = []\n",
    "for k in range(input_ids_t.shape[0]):\n",
    "    a = np.argmax(preds_start[k,])\n",
    "    b = np.argmax(preds_end[k,])\n",
    "    if a>b: \n",
    "        st = test.loc[k,'text']\n",
    "    else:\n",
    "        text1 = \" \"+\" \".join(test.loc[k,'text'].split())\n",
    "        enc = tokenizer.encode(text1)\n",
    "        st = tokenizer.decode(enc.ids[a-1:b])\n",
    "    all.append(st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>selected_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Last session of the day  http://twitpic.com/67ezh</td>\n",
       "      <td>itpic.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Shanghai is also really exciting (precisely -...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Recession hit Veronique Branquinho, she has to...</td>\n",
       "      <td>recession hit veronique branquinho, she has t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>happy bday!</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://twitpic.com/4w75p - I like it!!</td>\n",
       "      <td>http://twitpic.com/4w75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>that`s great!! weee!! visitors!</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I THINK EVERYONE HATES ME ON HERE   lol</td>\n",
       "      <td>on here</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>soooooo wish i could, but im in school and my...</td>\n",
       "      <td>soooooo wish i could, but im in school and my...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>and within a short time of the last clue all ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>What did you get?  My day is alright.. haven`...</td>\n",
       "      <td>leaving soon to my</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Last session of the day  http://twitpic.com/67ezh   \n",
       "1   Shanghai is also really exciting (precisely -...   \n",
       "2  Recession hit Veronique Branquinho, she has to...   \n",
       "3                                        happy bday!   \n",
       "4             http://twitpic.com/4w75p - I like it!!   \n",
       "5                    that`s great!! weee!! visitors!   \n",
       "6            I THINK EVERYONE HATES ME ON HERE   lol   \n",
       "7   soooooo wish i could, but im in school and my...   \n",
       "8   and within a short time of the last clue all ...   \n",
       "9   What did you get?  My day is alright.. haven`...   \n",
       "\n",
       "                                       selected_test  \n",
       "0                                          itpic.com  \n",
       "1                                                     \n",
       "2   recession hit veronique branquinho, she has t...  \n",
       "3                                                     \n",
       "4                            http://twitpic.com/4w75  \n",
       "5                                                     \n",
       "6                                            on here  \n",
       "7   soooooo wish i could, but im in school and my...  \n",
       "8                                                     \n",
       "9                                 leaving soon to my  "
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'text': test['text'][:10].values, 'selected_test': all})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tweet-sentiment-extraction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
