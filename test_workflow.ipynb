{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tweet_sentiment_service.model import SentimentModel\n",
    "from tweet_sentiment_service.inference import SentimentExtractor, SentimentID\n",
    "from tokenizers import ByteLevelBPETokenizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from fastapi.testclient import TestClient\n",
    "from tweet_sentiment_service.app import app"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Model Class only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 96\n",
    "PATH = './config/'\n",
    "\n",
    "tokenizer = ByteLevelBPETokenizer(\n",
    "    vocab=PATH+'vocab-roberta-base.json', \n",
    "    merges=PATH+'merges-roberta-base.txt', \n",
    "    lowercase=True,\n",
    "    add_prefix_space=True\n",
    ")\n",
    "sentiment_id = {'positive': 1313, 'negative': 2430, 'neutral': 7974}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing\n",
    "test = pd.read_csv('./training/test.csv').fillna('')\n",
    "tweet = test.loc[2, 'text'] #'Last session of the day  http://twitpic.com/67ezh'\n",
    "sentiment = 'negative'\n",
    "ct = 1\n",
    "input_ids = np.ones((ct,MAX_LEN),dtype='int32')\n",
    "attention_mask = np.zeros((ct,MAX_LEN),dtype='int32')\n",
    "token_type_ids = np.zeros((ct,MAX_LEN),dtype='int32')\n",
    "\n",
    "# INPUT_IDS\n",
    "text1 = \" \"+\" \".join(tweet.split())\n",
    "enc = tokenizer.encode(text1)\n",
    "s_tok = sentiment_id[sentiment]           \n",
    "input_ids[0,:len(enc.ids)+5] = [0] + enc.ids + [2,2] + [s_tok] + [2]\n",
    "attention_mask[0,:len(enc.ids)+5] = 1\n",
    "\n",
    "# Model Setup\n",
    "model = SentimentModel(weights_path=\"./weights_final.h5\", config_path=PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DISPLAY = 1\n",
    "predictions = model.predict(\n",
    "            input_ids=input_ids, \n",
    "            attention_mask=attention_mask, \n",
    "            token_type_ids=token_type_ids\n",
    "        )\n",
    "\n",
    "prediction_start = np.zeros((1,MAX_LEN))\n",
    "prediction_end = np.zeros((1,MAX_LEN))\n",
    "\n",
    "prediction_start += predictions[0]\n",
    "prediction_end += predictions[1]\n",
    "\n",
    "start_idx = np.argmax(prediction_start)\n",
    "end_idx = np.argmax(prediction_end)\n",
    "\n",
    "if start_idx > end_idx:\n",
    "    selected_text = tweet\n",
    "\n",
    "text = \" \"+\" \".join(tweet.split())\n",
    "encoded_text = tokenizer.encode(text)\n",
    "selected_text = tokenizer.decode(encoded_text.ids[start_idx-1:end_idx])\n",
    "\n",
    "print(selected_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Inference Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './config/'\n",
    "# Input\n",
    "test = pd.read_csv('./training/test.csv').fillna('')\n",
    "tweet = test.loc[2, 'text'] #'Last session of the day  http://twitpic.com/67ezh'\n",
    "sentiment = 'negative'\n",
    "\n",
    "# Inference\n",
    "sentiment_extractor = SentimentExtractor(weights_path=\"./weights_final.h5\", config_path=PATH)\n",
    "\n",
    "# Extract Sentiment from Tweet\n",
    "ans = sentiment_extractor.extract_sentiment(tweet=tweet, sentiment=sentiment)\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = TestClient(app=app)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 22:02:32.522893: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "All model checkpoint layers were used when initializing TFRobertaModel.\n",
      "\n",
      "All the layers of TFRobertaModel were initialized from the model checkpoint at ./config/pretrained-roberta-base.h5.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 5s 5s/step\n"
     ]
    }
   ],
   "source": [
    "from tweet_sentiment_service.app import SentimentRequest\n",
    "data = {\n",
    "    \"tweet\": \"Recession hit Veronique Branquinho, she has to quit her company, such a shame!\",\n",
    "    \"sentiment\": \"negative\",\n",
    "}\n",
    "response = client.post(url=\"/sentiment\", json=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'success',\n",
       " 'selected_text': ' recession hit veronique branquinho, she has to quit her'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFRobertaModel.\n",
      "\n",
      "All the layers of TFRobertaModel were initialized from the model checkpoint at ./config/pretrained-roberta-base.h5.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 6s 6s/step\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    \"tweet\": \"I went on a walk with my dog yesterday, and saw a homeless guy. So sad!\",\n",
    "    \"sentiment\": \"negative\",\n",
    "}\n",
    "response = client.get(url=\"/sentiment\", params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'selected_text': 'I went on a walk with my dog yesterday, and saw a homeless guy. So sad!'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install --upgrade anyio httpx starlette fastapi"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tweet-sentiment-extraction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
